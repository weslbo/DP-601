{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Reading Data - Parquet Files\n",
                "\n",
                "**Technical Accomplishments:**\n",
                "- Introduce the Parquet file format.\n",
                "- Read data from:\n",
                "  - Parquet files without a schema.\n",
                "  - Parquet files with a schema."
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "64b75646-01d5-4cb0-8b63-c075f63e379a"
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ➡️ Getting Started\n",
                "\n",
                "Run the following cell to configure our notebook"
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "303d4ec4-d0af-4fb4-abd5-e2fe2e1fdd52"
        },
        {
            "cell_type": "code",
            "source": [
                "%run Utilities"
            ],
            "outputs": [],
            "execution_count": null,
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "5705c47e-894f-45fb-9f93-d2115a07ee25"
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ➡️ Reading from Parquet Files\n",
                "\n",
                "<strong style=\"font-size:larger\">\"</strong>Apache Parquet is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language.<strong style=\"font-size:larger\">\"</strong><br>"
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "d6bce11d-624a-4566-9861-ce48149daa04"
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ➡️ About Parquet Files\n",
                "* Free & Open Source.\n",
                "* Increased query performance over row-based data stores.\n",
                "* Provides efficient data compression.\n",
                "* Designed for performance on large data sets.\n",
                "* Supports limited schema evolution.\n",
                "* Is a splittable \"file format\".\n",
                "\n",
                "**Row-oriented systems**\n",
                "\n",
                "A common method of storing a table is to serialize each row of data, like this:\n",
                "\n",
                "```text\n",
                "001:10,Smith,Joe,60000;\n",
                "002:12,Jones,Mary,80000;\n",
                "003:11,Johnson,Cathy,94000;\n",
                "004:22,Jones,Bob,55000;\n",
                "```\n",
                "\n",
                "**Column-oriented systems**\n",
                "\n",
                "A column-oriented database serializes all of the values of a column together, then the values of the next column, and so on. For our example table, the data would be stored in this fashion:\n",
                "\n",
                "```text\n",
                "10:001,12:002,11:003,22:004;\n",
                "Smith:001,Jones:002,Johnson:003,Jones:004;\n",
                "Joe:001,Mary:002,Cathy:003,Bob:004;\n",
                "60000:001,80000:002,94000:003,55000:004;\n",
                "```\n",
                "\n",
                "See also\n",
                "* <a href=\"https://parquet.apache.org/\" target=\"_blank\">https&#58;//parquet.apache.org</a>\n",
                "* <a href=\"https://en.wikipedia.org/wiki/Apache_Parquet\" target=\"_blank\">https&#58;//en.wikipedia.org/wiki/Apache_Parquet</a>"
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "8db47050-eeb3-45e0-b82b-6e014208127d"
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ➡️ Data Source\n",
                "\n",
                "The data for this example shows population data from UNHCR’s annual statistical activities dating back to 1951. Click [here](https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-08-22/readme.md) for more information"
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "045e3a11-4235-4904-a5e0-7376f5dcdca0"
        },
        {
            "cell_type": "code",
            "source": [
                "%%sh\n",
                "\n",
                "ls /lakehouse/default/Files/sampledata/population.parquet"
            ],
            "outputs": [],
            "execution_count": null,
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "15788914-515b-4542-90f4-f487fb480bc5"
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ➡️ Read in the Parquet File(s)\n",
                "\n",
                "To read in this files, we will specify the location of the parquet directory."
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "35574bb8-8acd-4108-989d-2496c76411b9"
        },
        {
            "cell_type": "code",
            "source": [
                "parquetFile = \"Files/sampledata/population.parquet\"\n",
                "\n",
                "parquetDF = (spark.read              # The DataFrameReader\n",
                "                .parquet(parquetFile)  # Creates a DataFrame from Parquet after reading in the file\n",
                "            )\n",
                "\n",
                "parquetDF.printSchema()         # Print the DataFrame's schema"
            ],
            "outputs": [],
            "execution_count": null,
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "332f9d67-d1c0-4b95-afac-0e60c2f0c984"
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ➡️ Review: Reading from Parquet Files\n",
                "* We do not need to specify the schema - the column names and data types are stored in the parquet files.\n",
                "* Only one job is required to **read** that schema from the parquet file's metadata.\n",
                "* Unlike the CSV or JSON readers that have to load the entire file and then infer the schema, the parquet reader can \"read\" the schema very quickly because it's reading that schema from the metadata."
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "ae3e5c03-1169-497b-b13f-0a7794ba7ccd"
        },
        {
            "cell_type": "markdown",
            "source": [
                "In most/many cases, people do not provide the schema for Parquet files because reading in the schema is such a cheap process.\n",
                "\n",
                "And lastly, let's peek at the data:"
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "e261c5e8-ca82-42b4-b803-823ff786685f"
        },
        {
            "cell_type": "code",
            "source": [
                "display(parquetDF)"
            ],
            "outputs": [],
            "execution_count": null,
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                },
                "collapsed": false
            },
            "id": "cd10e50e-c19d-4aff-9208-02bd9d7ea018"
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        },
        "kernelspec": {
            "name": "synapse_pyspark",
            "display_name": "Synapse PySpark"
        },
        "microsoft": {
            "host": {},
            "language": "python",
            "ms_spell_check": {
                "ms_spell_check_language": "en"
            }
        },
        "widgets": {},
        "kernel_info": {
            "name": "synapse_pyspark"
        },
        "nteract": {
            "version": "nteract-front-end@1.0.0"
        },
        "save_output": true,
        "spark_compute": {
            "compute_id": "/trident/default",
            "session_options": {
                "enableDebugMode": false,
                "conf": {}
            }
        },
        "notebook_environment": {},
        "synapse_widget": {
            "version": "0.1",
            "state": {}
        },
        "trident": {
            "lakehouse": {}
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}