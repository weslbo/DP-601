{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Reading Data - Tables and Views\n",
                "\n",
                "**Technical Accomplishments:**\n",
                "* Demonstrate how to pre-register data sources in Microsoft Fabric\n",
                "* Introduce temporary views over files.\n",
                "* Read data from tables/views.\n",
                "* Regarding `printRecordsPerPartition(..)`, it \n",
                "  * converts the specified `DataFrame` to an RDD\n",
                "  * counts the number of records in each partition\n",
                "  * prints the results to the console."
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "f2fa987a-216a-4c33-8a08-bd39fed9726f"
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ➡️ Getting Started\n",
                "\n",
                "Run the following cell to configure our notebook."
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "9ac3c70d-af78-4b47-8133-45beabfb0573"
        },
        {
            "cell_type": "code",
            "source": [
                "%run Utilities"
            ],
            "outputs": [],
            "execution_count": null,
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "a1f3c9fe-386f-4170-a12c-7f3bb5e06771"
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ➡️ Upload a CSV file to the Lakehouse\n",
                "\n",
                "1. Download the \"Taxi Zone Lookup Table\" CSV file from [here](https://github.com/weslbo/DP-601/raw/main/data/taxi_zone_lookup.csv), and save to a location in your computer.\n",
                "\n",
                "1. Create the `TaxiData` folder under the Files section of your Lakehouse.\n",
                "\n",
                "1. Upload the file to the folder, by using the Upload file item in the folder contextual menu.\n",
                "\n",
                "1. Once uploaded, select the folder to see its content."
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "6f5194e8-e3e6-4b66-bafd-9e30f4ccfb0f"
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ➡️ Load the file to a Delta table\n",
                "\n",
                "1. Right-click or use the ellipsis on the CSV file to access the contextual menu. Select Load to Tables and choose the New table option.\n",
                "\n",
                "1. The load to tables user interface shows up with the suggested table name. Real time validations on special characters apply during typing.\n",
                "\n",
                "1. Select Load to execute the load.\n",
                "\n",
                "1. The table now shows up in the lakehouse explorer, expand the table to see the columns and its types. Select the table to see a preview."
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "80cac5bb-d10f-45e0-b3a7-7a7f30874c40"
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ➡️ Reading from a Table/View\n",
                "\n",
                "We can now read in the \"table\" **taxi_zone_lookup** as a `DataFrame` with one simple command (and then print the schema):"
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "1e425fcf-3e28-4ef5-bdb7-57331f641e6e"
        },
        {
            "cell_type": "code",
            "source": [
                "taxi_zone_lookup_DF = spark.read.table(\"taxi_zone_lookup\")\n",
                "taxi_zone_lookup_DF.printSchema()"
            ],
            "outputs": [],
            "execution_count": null,
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "da63b6c0-5fa5-4941-8183-5436755cfeec"
        },
        {
            "cell_type": "markdown",
            "source": [
                "And of course we can now view that data as well:"
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "b8de60a6-361c-49b9-99a0-739915474ce6"
        },
        {
            "cell_type": "code",
            "source": [
                "display(taxi_zone_lookup_DF)"
            ],
            "outputs": [],
            "execution_count": null,
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                },
                "collapsed": false
            },
            "id": "8d732aca-d7f0-4f0b-9481-01f78e75c4fb"
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's take a look at some of the other details of the `DataFrame` we just created for comparison sake."
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "ba28a233-b473-4399-8650-9daa86417c51"
        },
        {
            "cell_type": "code",
            "source": [
                "print(\"Partitions: \" + str(taxi_zone_lookup_DF.rdd.getNumPartitions()))\n",
                "print(\"-\"*80)"
            ],
            "outputs": [],
            "execution_count": null,
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "906d379c-55e0-49e5-a026-e7290001110c"
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ➡️ Displaying data\n",
                "\n",
                "Tables that are loadable by the call `spark.read.table(..)` are also accessible through the SQL APIs.\n",
                "\n",
                "For example, we already used Microsoft Fabric to expose **taxi_zone_lookup** as a table/view."
            ],
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "id": "360badb2-aef5-4aec-b1f5-0a5b2eda2c50"
        },
        {
            "cell_type": "code",
            "source": [
                "%%sql\n",
                "\n",
                "select * from taxi_zone_lookup limit(5)"
            ],
            "outputs": [],
            "execution_count": null,
            "metadata": {
                "jupyter": {
                    "source_hidden": false,
                    "outputs_hidden": false
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                },
                "microsoft": {
                    "language": "sparksql"
                },
                "collapsed": false
            },
            "id": "0c13c5ae-c230-4594-9fca-7c6eb60ba0eb"
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        },
        "kernelspec": {
            "name": "synapse_pyspark",
            "display_name": "Synapse PySpark"
        },
        "microsoft": {
            "host": {},
            "language": "python",
            "ms_spell_check": {
                "ms_spell_check_language": "en"
            }
        },
        "widgets": {},
        "kernel_info": {
            "name": "synapse_pyspark"
        },
        "nteract": {
            "version": "nteract-front-end@1.0.0"
        },
        "save_output": true,
        "spark_compute": {
            "compute_id": "/trident/default",
            "session_options": {
                "enableDebugMode": false,
                "conf": {}
            }
        },
        "notebook_environment": {},
        "synapse_widget": {
            "version": "0.1",
            "state": {}
        },
        "trident": {
            "lakehouse": {}
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}